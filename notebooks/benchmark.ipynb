{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "tests = {\n",
    "    'devices': [torch.device('cpu')],\n",
    "    'parallel_envs': [1, 128, 1024, 8192]\n",
    "}\n",
    "\n",
    "def test_evaluator(n_times, evaluator, device, parallel_envs):\n",
    "    timings = []\n",
    "    for _ in range(n_times):\n",
    "        completed = torch.zeros(parallel_envs, dtype=torch.bool, device=device, requires_grad=False)\n",
    "        while not completed.all():\n",
    "            start_time = time.time()\n",
    "            _, _, _, _, terminated = evaluator.step()\n",
    "            tot_time = time.time() - start_time\n",
    "            timings.append(tot_time)\n",
    "            completed |= terminated\n",
    "    \n",
    "    return parallel_envs / (sum(timings) / len(timings)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.algorithms.load import init_evaluator\n",
    "from envs.load import init_env\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tests['devices'].append(torch.device('cuda'))\n",
    "\n",
    "results = dict()\n",
    "for device in tests['devices']:\n",
    "    for n_envs in tests['parallel_envs']:\n",
    "        env = init_env(device, n_envs, {'env_type': 'othello', 'board_size': 8}, False)\n",
    "        evaluator = init_evaluator({'name': 'random'}, env) \n",
    "        result = test_evaluator(10, evaluator, device, n_envs)\n",
    "        results[(str(device), n_envs)] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(range(len(results)), list(results.values()), align='center')\n",
    "plt.xticks(range(len(results)), list(results.keys()))\n",
    "plt.ylabel('Steps/Second')\n",
    "plt.xlabel('Device, # Envs')\n",
    "plt.title('Othello Env Benchmark')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turbozero-mMa0U6zx-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
